{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4b7d3bc0-8872-4cc6-9233-5d1ceddfe813",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Model training from aggregate features\n",
    "\n",
    "This notebook will take us through an example model training with a popular [mlflow built-in model flavor](https://mlflow.org/docs/latest/models.html#built-in-model-flavors) [xgboost](https://mlflow.org/docs/latest/models.html#xgboost-xgboost).\n",
    "\n",
    "The modules that we had sone discovery on have been updated to be loaded from a python module. This is helpful to assure reproducability. However, an even better pattern is to package and version the python modules in whl and import from the installed whl.\n",
    "\n",
    "The following sections will take us through through training a model. The data science here is a little non-sensical, however the model is actually trained and is representative of the same python class that will be used in production deployments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ddd91c-c128-4c2f-88f4-e287d239d3cd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Run Setup"
    }
   },
   "outputs": [],
   "source": [
    "%run ./_setup/setup_patient_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c5b62833-1c18-4bac-b7f7-153a6fecad1b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Create Test & Training Sets"
    }
   },
   "outputs": [],
   "source": [
    "from patient_features.agg_func import sliding_window_numeric_aggregates\n",
    "from pyspark.sql.functions import min, max, mean\n",
    "\n",
    "patient_response = spark.table(\"main.default.patient_response\")\n",
    "patient_lab = spark.table(\"main.default.patient_lab\")\n",
    "\n",
    "\n",
    "train_data, test_data = sliding_window_numeric_aggregates(\n",
    "                                        patient_event_df=patient_response,\n",
    "                                        patient_lab=patient_lab,\n",
    "                                        agg_funcs=[min, max, mean],\n",
    "                                        lab_types=['ua_ph',],\n",
    "                                        windows_in_days=[12*30, 9*30]) \\\n",
    "                            .join(patient_response, on=['patient_id', 'event_ts'], how='left') \\\n",
    "                            .drop('patient_id', 'event_ts') \\\n",
    "                            .randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d047c9b1-6de6-4030-b6f6-24c5ab385f5a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Train Model"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Turn off mlflow autologging\n",
    "mlflow.autolog(disable=True)\n",
    "\n",
    "# Convert Spark DataFrames to Pandas DataFrames\n",
    "train_data_pd = train_data.toPandas()\n",
    "test_data_pd = test_data.toPandas()\n",
    "\n",
    "# Separate features and target variable\n",
    "X_train = train_data_pd.drop('is_sick', axis=1)\n",
    "y_train = train_data_pd['is_sick']\n",
    "X_test = test_data_pd.drop('is_sick', axis=1)\n",
    "y_test = test_data_pd['is_sick']\n",
    "\n",
    "# Train the XGBoost model\n",
    "model = xgb.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf2d402f-8a66-4ac7-9084-7a7f635fc114",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Create Experiment & Log Model\n",
    "\n",
    "While it is possible to log models directly to a notebook, in this example, we'll save to a workspace experiment. This will create an experiment location in a workspace path. This is helpful when you are going to have experiments from multiple notebooks that are in consideration for best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4e5bdce-92b4-4372-acb8-714eaedffff8",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get or Create Experiment"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"databricks\",\n",
    "                      registry_uri=\"databricks-uc\")\n",
    "\n",
    "model_name=\"patient_lab_sick\"\n",
    "experiment_name = f\"/Workspace/experiments/{model_name}\"\n",
    "\n",
    "try:\n",
    "    experiment_id = client.create_experiment(name=experiment_name[10:])\n",
    "    experiment = client.get_experiment(experiment_id=experiment_id)\n",
    "except:\n",
    "    experiment = client.search_experiments(filter_string=f'name=\"{experiment_name[10:]}\"')[0]\n",
    "    experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6f65cb18-804c-4695-9f03-0bbde423f952",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Log and Register Model\n",
    "\n",
    "In mlflow you are able to separate the model logging to an experiment run and registry process. This is typically done when there is a desire to retain many experiments, but only promote the best model selected as a registered model. Since there are permission differences between the two entities, this is a good governanace pattern to keep the DS team aware of all experiments, but only the registered model avaialble outside of the DS team.\n",
    "\n",
    "That topic is outside the scope of this repo. To find out more, goto [Manage model lifecycle in Unity Catalog](https://docs.databricks.com/en/machine-learning/manage-model-lifecycle/index.html#manage-model-lifecycle-in-unity-catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "093a9351-cefd-45d2-b7a9-19da02e1655f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Infer the model signature\n",
    "signature = infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "# Log the model and metrics to MLflow\n",
    "with mlflow.start_run(experiment_id=experiment_id):\n",
    "    mlflow.xgboost.log_model(xgb_model=model,\n",
    "                             artifact_path=\"xgb_model\", \n",
    "                             input_example=X_train.iloc[[0]],\n",
    "                             model_format=\"ubj\",\n",
    "                             registered_model_name=f\"main.default.{model_name}\",\n",
    "                             signature=signature)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_model_training",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
