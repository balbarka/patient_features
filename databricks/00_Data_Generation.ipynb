{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6644a059-b85b-4cb8-b8ae-f50278bfc36b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Data Generation\n",
    "\n",
    "To evaluate how we can create features from point in time data , we'll want to create two datasets that are representative of Health Care data. Specifically:\n",
    " - `main.default.patient_lab` - This will include generated patient lab results\n",
    " - `main.default.patient_lab` - \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88513e0c-c19d-4ca8-917b-439e3c49b884",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## `patient_lab`\n",
    "\n",
    "| Lab | lab_types | Description |\n",
    "| --- | -------- | ----------- |\n",
    "| Urinalysis (UA) | `ua_ph`</br>`ua_protein`</br>`ua_glucose`</br>`ua_ketones`| Analyzes urine components; pH, protein, glucose, ketones |\n",
    "| Blood Urea Nitrogen (BUN) | `bun` | Measures kidney function. |\n",
    "| Creatinine | `creatinine` | Waste product indicating kidney function. |\n",
    "| Glomerular Filtration Rate (GFR) | `gfr` | Estimates kidney function efficiency. |\n",
    "\n",
    "First, we'll create a table that has a typical format which is that each lab results has it's own record. To demo functionality, we'll generate some sample data. To be able to later test the scalability of the solution, you can adjust the configurations in the generation code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2859ab9-30ba-4de9-886a-c5f8b22e62b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS main.default.patient_lab (\n",
    "    patient_id LONG    COMMENT \"Unique identifier for a patient\",\n",
    "    event_ts TIMESTAMP COMMENT \"Timestamp of when the lab was sample was taken\",\n",
    "    lab_type STRING    COMMENT \"The specific lab metric recorded\",\n",
    "    lab_value STRING   COMMENT \"The numeric reulsts of the lab_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c48c2f77-d063-4125-965d-5a5bf33c7c60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Function to generate random dates within a year, ensuring at least one week apart\n",
    "def generate_random_dates(year, num_dates):\n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date = datetime(year, 12, 31)\n",
    "    dates = []\n",
    "    while len(dates) < num_dates:\n",
    "        random_date = start_date + timedelta(days=random.randint(0, (end_date - start_date).days))\n",
    "        if all(abs((random_date - d).days) >= 7 for d in dates):\n",
    "            dates.append(random_date)\n",
    "    return sorted(dates)\n",
    "\n",
    "# Generate sample data\n",
    "data = []\n",
    "patient_ids = range(1, 11)\n",
    "years = [2023, 2024]\n",
    "lab_types = ['ua_ph', 'ua_protein', 'ua_glucose', 'ua_ketones']\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    for year in years:\n",
    "        dates = generate_random_dates(year, 5)\n",
    "        for date in dates:\n",
    "            lab_data = {\n",
    "                'patient_id': patient_id,\n",
    "                'date': date,\n",
    "                'ua_ph': round(random.uniform(4.5, 8.0), 1),  # Normal range for urine pH\n",
    "                'ua_protein': random.choice(['negative', 'trace', '1+', '2+', '3+']),  # Normal is 'negative' or 'trace'\n",
    "                'ua_glucose': random.choice(['negative', 'trace', '1+', '2+', '3+']),  # Normal is 'negative'\n",
    "                'ua_ketones': random.choice(['negative', 'trace', '1+', '2+', '3+'])   # Normal is 'negative'\n",
    "            }\n",
    "            data.append(lab_data)\n",
    "\n",
    "# Define lab_data Spark DataFrame\n",
    "lab_data = spark.createDataFrame(pd.DataFrame(data)) \\\n",
    "                .withColumnRenamed('date', 'event_ts') \\\n",
    "                .withColumn(\"ua_ph\", col(\"ua_ph\").cast(\"bigint\")) \\\n",
    "                .withColumn(\"ua_ph\", col(\"ua_ph\").cast(\"string\")) \\\n",
    "                .selectExpr(\"patient_id\",\n",
    "                            \"event_ts\",\n",
    "                            \"\"\"stack(4, 'ua_ph', ua_ph,\n",
    "                                        'ua_protein', ua_protein,\n",
    "                                        'ua_glucose', ua_glucose,\n",
    "                                        'ua_ketones', ua_ketones) as (lab_type, lab_value)\"\"\")                             \n",
    "\n",
    "# Write lab_data to Delta Lake\n",
    "lab_data.write.mode(\"overwrite\").saveAsTable(\"main.default.patient_lab\")\n",
    "\n",
    "# Display the DataFrame\n",
    "# display(lab_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8836f7-d800-41e2-afb6-1f26210bfd74",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM main.default.patient_lab limit 8;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64cd7b05-3e2c-4e15-ba54-db45313fcb33",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## `patient_event`\n",
    "\n",
    "The records for patient event will include at a minimum the unique identifier for the patient, `patient_id`, and the time of the event, `event_ts`.\n",
    "\n",
    "**NOTE**: While both the labs table and the patient_event table will both have the field `event_ts`, these fields will likely not matching and have different meanings. Specifically:\n",
    " - labs_tsdf `event_ts`: The time that lan sample was taken and evaluated. \n",
    " - patient_event `event_ts`: The event time that would trigger an evaluation. This could be any event time when a model may be run requiring augmented features. For example, a patient event where a model could be run would be at patient checkout to evaluate probability of readmittance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2a0e349-966b-4b40-85f8-df4a214ba396",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS main.default.patient_event (\n",
    "  patient_id STRING COMMENT \"Unique identifier for a patient\",\n",
    "  last_name STRING COMMENT \"Patient's last name\",\n",
    "  first_name STRING COMMENT \"Patient's first name\",\n",
    "  event_ts TIMESTAMP COMMENT \"Timestamp of the event\");\n",
    "\n",
    "INSERT OVERWRITE main.default.patient_event\n",
    "    VALUES ('3', 'Smith', 'John', '2024-01-18 12:00:00'),\n",
    "           ('5', 'Mary',  'Mac',  '2024-02-11 12:00:00');\n",
    "\n",
    "SELECT * FROM main.default.patient_event;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7440668743606110,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "00_Data_Generation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
